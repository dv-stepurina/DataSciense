# Data Analysis Portfolio

## Overview
Two production-grade data analysis projects demonstrating complete analytics workflows from data extraction to actionable insights.

---

## Project 1: Educational Platform Analytics
**Business Impact**  
Identified 27% increase in student engagement after new feature launch, leading to feature expansion to all users.

** Technical Implementation**  
```python
# Sample A/B Test Analysis
effect_size = (test_group.mean() - control_group.mean()) / pooled_std
print(f"Cohen's d: {effect_size:.2f}")  # >>> Cohen's d: 0.45
```
# Core Technologies

| Category       | Tools                          |
|---------------|--------------------------------|
| **Database**  | SQLite, SQLAlchemy ORM         |
| **Analysis**  | Pandas, SciPy, Jupyter         |
| **Visualization** | Matplotlib, Plotly         |
| **Optimization** | Query planning, Index tuning |

# Key Findings

- **Peak engagement**: 14:00-17:00 (Weekdays)  
- **Submission speed**: 40% faster from top-engaged users  
- **Strong correlation**: r=0.72 between views and early submissions  

# Project 2: Automotive Data Optimization

## Performance Gains

```diff
+ Memory: 48MB ‚Üí 17MB (65% reduction)
+ Speed: 12.8s ‚Üí 4.1s (3.2x faster)
```
# üß† Advanced Techniques

## Memory Optimization
```python
# Optimize memory usage by downcasting numeric columns and using categorical types
df['fine'] = pd.to_numeric(df['fine'], downcast='float')
df['make'] = df['make'].astype('category')
```
## üîç Feature Engineering

### Temporal Feature Extraction
- Derived **15 time-based features** from timestamps including:
  - Day of week
  - Hour of day
  - Weekend flag
  - Time since last violation
  - Seasonal indicators

### Vehicle Data Processing
```python
# Automated make/model separation
df['make'], df['model'] = zip(*df['vehicle'].apply(lambda x: x.split(' ', 1)))
```
# Dataset Profile  

## Key Statistics:  
- **Total records**: 52,000+ traffic violations  

## Data enrichment:  
- **Original features**: 12  
- **After processing**: 28 features  

## Processing improvements:  
- Migrated from **daily batch processing**  
- Implemented **real-time capable pipeline**  
- Reduced latency from **hours to seconds**  

# How to Use
1. Clone repository
2. Install requirements: pip install -r requirements.txt
3. Run Jupyter notebooks in folders 
